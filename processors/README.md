# üß† Procesadores del Proyecto OpenMedia

Este m√≥dulo contiene todos los **processors** encargados de transformar, enriquecer y persistir los datos extra√≠dos por el sistema de scraping, bas√°ndose en una arquitectura **Pub/Sub + PostgreSQL (pgvector)**.

Cada processor es un microcomponente aut√≥nomo que escucha un t√≥pico espec√≠fico de Kafka, ejecuta un tipo de procesamiento (resumen, embeddings, calidad, etc.) y guarda los resultados en las tablas normalizadas del esquema `news` y relacionadas.

---

## üì¶ Estructura del m√≥dulo

```
processors/
‚îú‚îÄ‚îÄ base/             # Interfaces y utilidades compartidas entre processors
‚îÇ   ‚îú‚îÄ‚îÄ processor_interface.py
‚îÇ   ‚îî‚îÄ‚îÄ utils.py
‚îú‚îÄ‚îÄ common/           # Modelos, config y almacenamiento compartido
‚îÇ   ‚îú‚îÄ‚îÄ models.py
‚îÇ   ‚îú‚îÄ‚îÄ storage.py
‚îÇ   ‚îú‚îÄ‚îÄ config.py
‚îÇ   ‚îî‚îÄ‚îÄ embeddings.py
‚îú‚îÄ‚îÄ vector/           # Processor que genera y guarda embeddings sem√°nticos
‚îÇ   ‚îú‚îÄ‚îÄ processor.py
‚îÇ   ‚îú‚îÄ‚îÄ handler.py
‚îÇ   ‚îî‚îÄ‚îÄ consumer.py
‚îú‚îÄ‚îÄ summary/          # Processor que genera res√∫menes autom√°ticos
‚îú‚îÄ‚îÄ quality/          # Processor que eval√∫a calidad period√≠stica
‚îî‚îÄ‚îÄ hashtags/         # Processor que genera etiquetas autom√°ticas
```

---

## üöÄ ¬øC√≥mo funciona cada processor?

Cada carpeta contiene un `processor.py` que implementa la l√≥gica, un `handler.py` que act√∫a como adaptador del mensaje, y un `consumer.py` que escucha desde Kafka:

```
Kafka Topic ‚Üí consumer.py ‚Üí handler.py ‚Üí processor.py ‚Üí PostgreSQL
```

Todos los processors implementan la interfaz com√∫n `ProcessorInterface` que define:

```python
async def process(self, payload: dict) -> Any:
    ...
```

---

## ‚úÖ Reglas de dise√±o

- Cada processor debe ser **aut√≥nomo y desacoplado**.
- Debe almacenar en la base de datos solo lo que le corresponde (embeddings, resumen, scores, etc.).
- Puede compartir l√≥gica v√≠a `common/` (embeddings, modelos, storage, config).
- Puede extender la interfaz base desde `base/processor_interface.py`.

---

## üß™ Pruebas

Cada processor puede ser testeado de forma independiente ejecutando su `handler.py` con datos de ejemplo, o simulado en tests.

---

## üìö Documentaci√≥n complementaria

- [Estructura de base de datos en SQL](../database/OpenMedia_v0.2.sql)
- [Dise√±o de arquitectura general](../.docs/diagrams/processors/perplexity-research.md)

---

## üê≥ Uso con Docker Compose

Este m√≥dulo est√° dise√±ado para ser ejecutado con un `Dockerfile` √∫nico, ubicado en `processors/Dockerfile`, que puede ser reutilizado por m√∫ltiples servicios Docker.

Cada processor define su punto de entrada modificando el comando de ejecuci√≥n:

```yaml
command: ["python", "-m", "vector.consumer"]
```

Por ejemplo, para lanzar el `summary.processor` en Docker Compose:

```yaml
summary-processor:
  build:
    context: ./processors
    dockerfile: Dockerfile
  command: ["python", "-m", "summary.consumer"]
  environment:
    KAFKA_TOPIC: summary.topic
    ...
```

Aseg√∫rate de que todos los m√≥dulos tengan un `__init__.py` para que puedan ser importados correctamente como paquetes de Python (`python -m`).

El contexto del build debe ser `./processors`, ya que el `Dockerfile` se encuentra ah√≠, y as√≠ se asegura que los m√≥dulos `common/`, `base/` y todos los `processor/` est√©n disponibles.

---